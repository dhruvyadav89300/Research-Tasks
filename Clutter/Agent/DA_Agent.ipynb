{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgpoI1mWQbJW"
      },
      "source": [
        "## DA Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yhGe9WnRqzWK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import os\n",
        "from groq import Groq\n",
        "import json\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nA3Ld_RedFXe"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "os.environ[\"GROQ_API_KEY\"] = os.environ.get('GROQ_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2j42BuIuTtIv"
      },
      "outputs": [],
      "source": [
        "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Yd9KIZUrq-kv"
      },
      "outputs": [],
      "source": [
        "class DataAnalysisAgent:\n",
        "  def __init__(self, model):\n",
        "    self.data = None\n",
        "    self.data_type = None\n",
        "    self.analysis_results = {}\n",
        "    self.supported_types = [\"tabular\", \"json\"]\n",
        "    self.model = model\n",
        "    self.client = Groq()\n",
        "\n",
        "  def load_data(self, data_path: str):\n",
        "    try:\n",
        "      path = Path(data_path)\n",
        "\n",
        "      if path.suffix == \".csv\":\n",
        "        self.data = pd.read_csv(path)\n",
        "        self.data_type = \"tabular\"\n",
        "      elif path.suffix == \".xlsx\" or path.suffix == \"xls\":\n",
        "        self.data = pd.read_excel(path)\n",
        "        self.data_type = \"tabular\"\n",
        "      elif path.suffix == \".json\":\n",
        "        self.data = pd.read_json(path)\n",
        "        self.data_type = \"json\"\n",
        "      else:\n",
        "        raise Exception(\"File type not supported yet\")\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception(f\"Error loading data: {str(e)}\")\n",
        "\n",
        "  # def get_columns_type(self):\n",
        "  #   dtypes_dict = self.data.dtypes.to_dict()\n",
        "  #   data_map = {}\n",
        "  #   for key, value in dtypes_dict.items():\n",
        "  #     if str(value) == \"float64\" or \"int64\":\n",
        "  #       data_map[str(key)] = \"numerical\"\n",
        "  #     elif str(value) == \"bool\":\n",
        "  #       data_map[str(key)] = \"bool\"\n",
        "  #     elif str(value) == \"object\":\n",
        "  #       data_map[str(key)] = \"categorical\"\n",
        "  #   return data_map\n",
        "\n",
        "\n",
        "  # I am still trying to fix these\n",
        "  def plot_distribution(self, column):\n",
        "    if column not in self.data.columns:\n",
        "      raise Exception(\"Column not present in the dataset\")\n",
        "    else:\n",
        "      sns.histplot(self.data[column], kde=True)\n",
        "      plt.title(f\"Distribution of {column}\")\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  def analyze(self):\n",
        "    numeric_cols = self.data.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "    analysis = {\n",
        "        'summary_stats': self.data.describe(include=\"all\").to_dict(),\n",
        "        'missing_values': self.data.isnull().sum().to_dict(),\n",
        "        'unique_values': {col: self.data[col].nunique() for col in self.data.columns},\n",
        "        'skewness': self.data.skew().to_dict(),\n",
        "        'kurtosis': self.data.kurtosis().to_dict()\n",
        "    }\n",
        "    if len(numeric_cols) > 1:\n",
        "      analysis['correlations'] = self.data[numeric_cols].corr().to_dict()\n",
        "    for key, value in analysis.items():\n",
        "      self.analysis_results[key] = value\n",
        "    return analysis\n",
        "\n",
        "  def _format_results(self, results, indent: int = 0) -> str:\n",
        "      \"\"\"Format analysis results for the report.\"\"\"\n",
        "      formatted = []\n",
        "      for key, value in results.items():\n",
        "          if isinstance(value, dict):\n",
        "              formatted.append(f\"{'  ' * indent}- {key}:\")\n",
        "              formatted.append(self._format_results(value, indent + 1))\n",
        "          else:\n",
        "              formatted.append(f\"{'  ' * indent}- {key}: {value}\")\n",
        "      return \"\\n\".join(formatted)\n",
        "\n",
        "  def generate_report(self) -> str:\n",
        "        \"\"\"Generate a comprehensive analysis report.\"\"\"\n",
        "\n",
        "        report = [\n",
        "            \"# Data Analysis Report\",\n",
        "            \"\\n## Dataset Overview\",\n",
        "            f\"- Data Type: {self.data_type}\",\n",
        "            f\"- Dataset Shape: {self.data.shape}\"\n",
        "        ]\n",
        "\n",
        "        # Add type-specific metadata\n",
        "        if self.data_type == 'tabular':\n",
        "          report.extend([\n",
        "              f\"- Rows: {self.data.shape[0]}\",\n",
        "              f\"- Columns: {self.data.shape[1]}\",\n",
        "              \"\\n### Column Types:\",\n",
        "          ])\n",
        "            # report.extend([\n",
        "\n",
        "            #     \"\\n### Column Types:\",\n",
        "            #     *[f\"- {k}: {len(v)} columns\" for k, v in self.metadata['column_types'].items() if v]\n",
        "            # ])\n",
        "\n",
        "        # Add analysis results\n",
        "        report.append(\"\\n## Analysis Results\")\n",
        "        for analysis_type, results in self.analysis_results.items():\n",
        "            report.extend([\n",
        "                f\"\\n### {analysis_type.title()}\",\n",
        "                self._format_results(results)\n",
        "            ])\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "  def run_conversation(self, query):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a data analysis agent. You have a few functions available for analysis. You take in the data, decide which function to use and do you best to answer the user's query about the data\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": query,\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    # Define the available tools or functions \n",
        "    tools = [\n",
        "        {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"analyze\",\n",
        "            \"description\": \"Performs a detailed analysis of the dataset stored in the class. It generates statistical summaries, missing value counts, unique value counts, skewness, kurtosis, and correlations for numeric columns, providing key insights for exploratory data analysis (EDA).\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},  \n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"generate_report\",\n",
        "            \"description\": \"Generates a comprehensive analysis report of the dataset stored in the class. The report includes dataset overview, column types, and detailed analysis results such as summary statistics, missing values, unique values, skewness, kurtosis, and correlations.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"plot_distribution\",\n",
        "            \"description\": \"Plots the distribution of a specified column in the dataset using a histogram with a KDE overlay. This is useful for visualizing the frequency distribution and the underlying data shape.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"column\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The name of the column for which the distribution is to be plotted.\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"column\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "    ]\n",
        "    response = self.client.chat.completions.create(\n",
        "        model=self.model,\n",
        "        messages=messages,\n",
        "        stream=False,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=4096\n",
        "    )\n",
        "    response_message = response.choices[0].message\n",
        "    tool_calls = response_message.tool_calls\n",
        "    if tool_calls:\n",
        "      available_functions = {\n",
        "            \"analyze\": self.analyze,\n",
        "            \"generate_report\": self.generate_report,\n",
        "            \"plot_distribution\": self.plot_distribution\n",
        "        }\n",
        "      messages.append(response_message)\n",
        "\n",
        "\n",
        "      for tool_call in tool_calls:\n",
        "        function_name = tool_call.function.name\n",
        "        function_to_call = available_functions.get(function_name)\n",
        "\n",
        "        if not function_to_call:\n",
        "            raise Exception(f\"Function {function_name} is not available.\")\n",
        "\n",
        "\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "\n",
        "        if function_name == \"analyze\":\n",
        "            function_response = json.dumps(function_to_call(), default=str)\n",
        "        elif function_name == \"generate_report\":\n",
        "            function_response = function_to_call()\n",
        "        elif function_name == \"plot_distribution\":\n",
        "            column = function_args.get(\"column\")\n",
        "            if not column:\n",
        "                raise Exception(\"Missing 'column' argument for plot_distribution.\")\n",
        "            function_response = function_to_call(column=column)\n",
        "        else:\n",
        "            raise Exception(f\"Unexpected function: {function_name}\")\n",
        "\n",
        "\n",
        "\n",
        "        messages.append(\n",
        "            {\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    second_response = self.client.chat.completions.create(\n",
        "        model=self.model,\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "\n",
        "    return second_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iW5MZ-IO6Zuw"
      },
      "outputs": [],
      "source": [
        "agent = DataAnalysisAgent(model=\"llama3-groq-70b-8192-tool-use-preview\")\n",
        "agent.load_data(\"/Users/dhruvyadav/Desktop/RAG Research/Agent/sample_data/california_housing_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z9nvstBJtZgP",
        "outputId": "66db86b7-442d-4ef3-b257-624486d28e30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The mean of the median_house_value is 207,300.91, the median is 180,400, and the standard deviation is 115,983.76.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run_conversation(query = \"What are the mean, median, and standard deviation of the median_house_value column?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "cAh6Ht4qxqzu",
        "outputId": "1b2edefd-c7b2-4e40-b109-e9bd899c3a4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"There are a few negative correlations in the dataset. For instance, there's a negative correlation between 'housing_median_age' and 'total_bedrooms' with a value of -0.320434. Also, 'housing_median_age' is negatively correlated with 'total_rooms' with a value of -0.360984. This suggests that as the median house age increases, the total number of bedrooms and rooms decreases.\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run_conversation(query = \"Is there any negative correlation between numerical columns? If so, which ones?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zR-3wjyiyfEF",
        "outputId": "d3d01111-ce28-4b95-c7a5-007a365aa152"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The average median house value for each category of ocean proximity is as follows:\\n- 'NEAR BAY' has a median house value of $405,000\\n- 'NEAR OCEAN' has a median house value of $450,000\\n- 'INLAND' has a median house value of $300,000\\n- 'ISLAND' has a median house value of $500,000\\n- 'NEAR LAKE' has a median house value of $350,000\\n- 'NEAR RIVER' has a median house value of $400,000\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run_conversation(query = \"What is the average median_house_value for each category of ocean_proximity?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJdyVEpXyq_M",
        "outputId": "6a85053b-e9ab-48bf-eae8-4b4d58bc2472"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The ocean_proximity category with the highest average median_income is 'NEAR OCEAN', with a mean median income of $4.35.\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run_conversation(query = \"Which ocean_proximity category has the highest average median_income?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87vkLF05GGN"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYP6pbIKQYiK"
      },
      "source": [
        "## RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rXuzxn5v5GwQ"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eBb5gZ5K-8ht"
      },
      "outputs": [],
      "source": [
        "class RAG:\n",
        "    data_agent: DataAnalysisAgent\n",
        "    model_name: str\n",
        "    pdf_directory: str\n",
        "\n",
        "    def __init__(self, data_agent: DataAnalysisAgent, model_name: str, pdf_directory: str):\n",
        "        self.data_agent = data_agent\n",
        "        self.model_name = model_name\n",
        "        self.pdf_directory = pdf_directory\n",
        "        self.vector_store = None\n",
        "\n",
        "    def load_and_process_pdfs(self):\n",
        "        loader = PyPDFDirectoryLoader(self.pdf_directory)\n",
        "        documents = loader.load()\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "        splits = text_splitter.split_documents(documents)\n",
        "\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        self.vector_store = FAISS.from_documents(splits, embeddings)\n",
        "\n",
        "    def create_chain(self):\n",
        "        llm = ChatGroq(\n",
        "            model_name=self.model_name\n",
        "        )\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Context: {context}\n",
        "        Data Analysis Results: {analysis_results}\n",
        "\n",
        "        Question: {input}\n",
        "\n",
        "        Provide an answer using both the context from the documents and the data analysis insights.\n",
        "        If the answer is not provided in the analysis and the context, then simply say so and suggest the best possible solution.\n",
        "        \"\"\")\n",
        "\n",
        "        document_chain = create_stuff_documents_chain(\n",
        "            llm=llm,\n",
        "            prompt=prompt\n",
        "        )\n",
        "\n",
        "        retrieval_chain = create_retrieval_chain(\n",
        "            self.vector_store.as_retriever(),\n",
        "            document_chain\n",
        "        )\n",
        "\n",
        "        return retrieval_chain\n",
        "\n",
        "    def query(self, question: str) -> str:\n",
        "        if not self.vector_store:\n",
        "            self.load_and_process_pdfs()\n",
        "\n",
        "        analysis_results = self.data_agent.analyze()\n",
        "        chain = self.create_chain()\n",
        "\n",
        "        response = chain.invoke({\n",
        "            \"input\": question,\n",
        "            \"analysis_results\": json.dumps(analysis_results, default=str)\n",
        "        })\n",
        "\n",
        "        return response[\"answer\"]\n",
        "\n",
        "    def get_data_distribution(self, column: str):\n",
        "        return self.data_agent.plot_distribution(column)\n",
        "\n",
        "    def get_full_report(self) -> str:\n",
        "        return self.data_agent.generate_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KEbnlnUX_Qq1"
      },
      "outputs": [],
      "source": [
        "rag = RAG(data_agent=agent, model_name=\"llama-3.1-8b-instant\", pdf_directory=\"/Users/dhruvyadav/Desktop/RAG Research/Agent/sample_data/pdfs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VS2zBBWUDK3O"
      },
      "outputs": [],
      "source": [
        "answer = rag.query(\"What are the mean, median, and standard deviation of the median_house_value column? Also, what is the best model for price prediction? How does the measures f central tendency affect the model selection?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdGfaXcKD4GV",
        "outputId": "bb80c444-0aa6-4692-a91b-9052bdec9d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context and data analysis results, we can answer the questions as follows:\n",
            "\n",
            "1. What are the mean, median, and standard deviation of the median_house_value column?\n",
            "\n",
            "From the data analysis results, we can see that the mean, median, and standard deviation of the median_house_value column are:\n",
            "\n",
            "- Mean: 207,300.91\n",
            "- Median: 180,400.0\n",
            "- Standard Deviation: 115,983.76\n",
            "\n",
            "2. What is the best model for price prediction?\n",
            "\n",
            "According to the context, the best model for price prediction is the Random Forest model, which has an MSE of 0.290 and takes the longest training time of 14.7 seconds. This model performs better than the Ridge Linear Model and Gradient Boosting model.\n",
            "\n",
            "3. How do the measures of central tendency affect the model selection?\n",
            "\n",
            "The measures of central tendency, such as mean, median, and standard deviation, provide insights into the distribution of the median_house_value column. The mean is higher than the median, indicating a positively skewed distribution. The standard deviation is also high, indicating a large amount of variation in the data.\n",
            "\n",
            "The measures of central tendency can affect the model selection in the following ways:\n",
            "\n",
            "- The positively skewed distribution may require a transformation of the data, such as log transformation, to improve the normality of the data and reduce the impact of outliers.\n",
            "- The high standard deviation may require a model that can handle high variance, such as a Random Forest model, which is more robust to outliers and high variance.\n",
            "- The high correlation between median_income and median_house_value (0.69) may indicate that the relationship between these two variables is non-linear, which may require a model that can capture non-linear relationships, such as a Random Forest model.\n",
            "\n",
            "In summary, the measures of central tendency provide insights into the distribution of the median_house_value column, which can inform the selection of the best model for price prediction.\n"
          ]
        }
      ],
      "source": [
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNE9yt3qEUt-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RAG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
